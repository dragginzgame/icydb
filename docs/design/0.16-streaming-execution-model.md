# 0.16 Streaming Execution Model

## 1. Purpose

Introduce a streaming execution pipeline inside the query engine.

Streaming execution replaces intermediate `Vec<DataKey>` and `Vec<DataRow>` materialization with pull-based iterator composition.

The objective is to:

* Reduce memory usage
* Reduce latency to first row
* Eliminate unnecessary materialization
* Preserve strict continuation invariants
* Preserve ordering semantics
* Maintain correctness guarantees from 0.12–0.15

This phase does **not** introduce:

* Public API streaming
* Async execution
* Aggregations
* Joins
* Cross-query continuation reuse
* Predicate pushdown expansion
* Execution planner rewrite

---

# 2. Design Constraints

This design explicitly avoids the failure modes from prior iterator attempts.

Streaming is allowed only when:

1. Continuation is physical (raw-bound rewrite).
2. Limit is traversal-native (pushdown-aware).
3. Ordering is guaranteed by access path.
4. Predicate filtering is clearly layered.

No iterator may combine:

* Predicate filtering
* Continuation tracking
* Limit counting
* Ordering enforcement

Those must remain separate layers.

---

# 3. High-Level Architecture

Execution becomes a pull-based pipeline:

```
AccessPlan
→ OrderedKeyIterator
→ RowLoaderIterator
→ PredicateFilterIterator (if needed)
→ LimitIterator (if not pushed down)
→ Materializer (for public API)
```

Each stage implements:

```
trait OrderedIterator {
    type Item;

    fn next(&mut self) -> Result<Option<Self::Item>, InternalError>;
}
```

The executor no longer builds intermediate Vecs.

---

# 4. Scope of Streaming in 0.16

Streaming is introduced only for:

* AccessPlan::Path
* IndexRange
* KeyRange
* FullScan
* IndexPrefix

Composite plans (Union/Intersection) remain materialized in 0.16.

Residual predicate paths are supported via filtering iterator.

---

# 5. Layer Responsibilities

## 5.1 OrderedKeyIterator

Source of ordered DataKey values.

Backed by:

* IndexRangeIterator
* KeyRangeIterator
* FullScanIterator

Responsibilities:

* Maintain strict monotonic order
* Enforce continuation anchor
* Enforce raw bound envelope
* Enforce traversal-level limit pushdown (if safe)

Must not:

* Load rows
* Apply predicate
* Count filtered rows

---

## 5.2 RowLoaderIterator

Wraps OrderedKeyIterator.

For each key:

* Loads DataRow
* Applies ReadConsistency
* Handles missing-row behavior

Must not:

* Reorder rows
* Track pagination
* Apply filtering

---

## 5.3 PredicateFilterIterator

Wraps RowLoaderIterator.

For each row:

* Evaluates predicate
* Emits only matching rows

Important rule:

Predicate filtering must not modify traversal semantics.

Limit behavior here applies only if pushdown was not safe.

---

## 5.4 LimitIterator (Fallback)

Wraps downstream iterator.

If limit was not pushed down at traversal level:

* Stops after N emitted rows.

If limit was pushed down:

* This layer is skipped.

---

## 5.5 Materializer

Final stage:

```
collect::<Vec<_>>()
```

Public APIs remain unchanged in 0.16.

Streaming is internal only.

---

# 6. Continuation Semantics

Continuation remains entirely in traversal layer.

Rules:

* ASC: rewrite lower bound to Excluded(anchor)
* DESC: rewrite upper bound to Excluded(anchor)
* Anchor never emitted
* Strict monotonicity enforced at traversal layer

No filtering layer may interfere with continuation behavior.

---

# 7. Limit Semantics

Two cases:

### Case A — Pushdown Safe

Limit is passed into traversal iterator.

Filtering layer does not need to track count.

### Case B — Pushdown Unsafe (residual predicate exists)

Traversal has no limit.

PredicateFilterIterator tracks count.

Important:

Continuation anchor must always reflect last emitted key, not last traversed key.

---

# 8. Executor Changes

Replace:

```
rows_from_access(...)
→ Vec<DataRow>
```

With:

```
let iter = iterator_from_access(...);
let rows = iter.collect::<Result<Vec<_>, _>>()?;
```

All internal logic becomes streaming.

No change to public API.

---

# 9. Safety Rules

To prevent prior complexity explosion:

1. Traversal and filtering must be separate layers.
2. Limit pushdown must only activate when predicate fully covered by index.
3. Continuation anchor always based on raw traversal key.
4. No iterator may modify ordering.
5. Composite plans remain materialized.

---

# 10. Invariants

Must hold:

1. Strict monotonic progression.
2. No duplicate emission.
3. Envelope adherence.
4. Anchor exclusion.
5. Order stability.
6. Parity with non-streaming execution.
7. Identical continuation tokens as 0.12/0.13.

---

# 11. Testing Requirements

Add streaming-specific tests:

### A. Parity

Unbounded streaming == materialized result.

### B. Pagination

Concatenated streaming pages == unbounded.

### C. DESC Parity

Reverse traversal streaming equals reversed materialized result.

### D. Residual Predicate

Streaming + residual predicate behaves identically to pre-0.16.

### E. Limit Pushdown

Pushdown path produces identical results to fallback limit.

---

# 12. Performance Expectations

Memory:

* From O(n) to O(1) for large scans.

Latency:

* First row available immediately.

CPU:

* Slight overhead from iterator layering.
* Significant savings for limited scans.

---

# 13. Non-Goals

0.16 will not:

* Introduce async/await
* Change public API to streaming
* Refactor planner
* Implement merge-based union
* Implement advanced predicate pushdown
* Introduce aggregation

---

# 14. Migration Strategy

1. Introduce iterator abstraction (0.15).
2. Convert IndexRange execution path first.
3. Convert KeyRange/FullScan.
4. Leave composite plans unchanged.
5. Replace Vec-building in executor with streaming.
6. Preserve public API behavior.

---

# 15. Success Criteria

All must hold:

* All 0.12 and 0.13 tests pass unchanged.
* All 0.14 DESC tests pass unchanged.
* No change in continuation tokens.
* No change in emitted order.
* No duplicate/missing rows.
* No off-by-one errors in pagination.

---

# 16. Architectural Principle

> Traversal produces ordered keys.
>
> Loading and filtering transform keys.
>
> Materialization is a consumer concern.

Streaming execution must preserve this separation.

---

# 17. Risk Assessment

Primary risks:

* Mixing filtering and limit incorrectly
* Incorrect continuation anchor when predicate filters rows
* Breaking pushdown gating logic
* Reintroducing logical-boundary resume

Mitigation:

* Keep continuation strictly traversal-level
* Keep predicate filtering stateless
* Keep limit counting separate
* Maintain strict monotonicity assertions

---

# 18. Outcome

After 0.16:

* Engine is fully pull-based internally.
* Memory usage no longer scales with result size.
* Ordered iterator abstraction is fully adopted.
