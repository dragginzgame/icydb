# IcyDB 0.30 — Execution Kernel Consolidation

## Status

- Stage: Active — Implementation In Progress
- Target: 0.30
- Scope: Unify all read execution under one kernel
- Explicit deferral: `GROUP BY` implementation is moved to 0.31
- Landed in-tree:
  - Kernel ownership: `ExecutionPlan` boundary, `ExecutionKernel` scaffold, kernel-owned residual retry, kernel-owned DISTINCT stream decoration, kernel-owned predicate compile policy, kernel-owned aggregate entrypoint delegation, and aggregate orchestration extraction into `executor/kernel/aggregate.rs`
  - Aggregate convergence: canonical `count_distinct_by` orchestration via `execute(...)`, shared aggregate streaming-input setup, shared aggregate fast-path fold helpers, shared aggregate materialized terminal helper, shared routed-stream aggregate fold helper, shared secondary-index probe/fallback fold helper, and removal of duplicate legacy aggregate kernel orchestration
  - Module decomposition: terminal-wrapper split from `load/aggregate/mod.rs`, dedicated aggregate contracts/orchestration/fast-path modules under `load/aggregate/`, and DISTINCT stream logic under `executor/kernel/distinct.rs`
- Remaining in 0.30: formal reducer contracts + kernel reducer runner, cursor-module consolidation, and deletion of legacy aggregate facades (`load/aggregate` orchestration wrappers) once reducers are the only entry

## 0.29 Audit Carryover

Moved from the `0.29` audit backlog into this milestone:

- route planner and aggregate module decomposition
- collapse parallel load/aggregate/count-distinct orchestration paths into one kernel
- centralize residual retry ownership in one runtime boundary
- centralize `DISTINCT` wrapping and ordered-key stream normalization ownership
- centralize strict-vs-subset predicate compile ownership in the kernel boundary

Already completed in `0.29.8` (not reworked here):

- residual retry duplication removed for current paths
- comparator-enforced `DISTINCT` monotonicity fix
- strict-vs-subset compile helper dedup + parity tests
- commit-marker corruption classification normalization

## 1. Executive Summary

0.24–0.29 introduced:

- Rich aggregate surface
- Index predicate compilation
- Route planner + fast-path ordering
- `DISTINCT` integration
- Conservative vs strict compile modes
- Extensive parity testing

Before 0.30 consolidation work, execution was fragmented across multiple read pipelines:

- Load pipeline
- Aggregate streaming path
- Aggregate materialized fallback path
- legacy `count_distinct_by` hybrid path (now removed in-tree during 0.30)
- Terminal wrappers that call `execute(plan)`
- Delete materialized path

0.30 will establish a single execution kernel for all read paths. This reduces drift risk, centralizes budgeting and predicate semantics, and creates a stable base for 0.31 `GROUP BY` work.

## 2. Current Problems (Motivation)

### 2.1 Multiple Execution Kernels

Today there are parallel flows that independently:

- Resolve access paths
- Apply predicate compile modes
- Enforce budgets
- Retry residuals
- Wrap `DISTINCT`
- Materialize rows
- Handle edge behavior slightly differently

This increases:

- Drift risk
- Complexity hotspots
- Cognitive load
- Future feature cost

### 2.2 Streaming Is Not Truly Streaming

Key materialization is eager today:

- `Vec<DataKey>`
- `VecOrderedKeyStream`
- Often `Vec<Row>` before ranking

Abstractions look streaming-oriented, but behavior is mostly bounded materialization.

This blocks:

- True incremental windowing
- Memory scaling improvements
- Efficient 0.31 `GROUP BY` streaming

### 2.3 Predicate Compile Boundary Is Scattered

Strict vs subset decisions appear in:

- Route planner
- Load execution
- Aggregate orchestration

Before this 0.30 slice, compile ownership was not centralized.

### 2.4 Aggregates Are a Special-Case System

Aggregate execution currently:

- Has its own fast-path dispatch
- Historically used hybrid logic for distinct/count (removed in-tree during 0.30)
- Has fallback orchestration
- Uses both streaming and materialized paths

It remains semi-parallel to load instead of unified under one kernel.

## 3. Design Goals for 0.30

### Primary Goals

- One execution kernel for all read paths
- Centralize routing + streaming + materialization decisions
- Make fold/reducer behavior pluggable
- Preserve 0.29 semantics and tests
- Keep 0.30 as an enablement release for 0.31 `GROUP BY`

### Non-Goals (0.30 Scope Boundary)

- Full pull-based streaming rewrite
- Disk spill or out-of-core grouping
- Major index redesign
- Commit protocol redesign
- Full `GROUP BY` query surface (moved to 0.31)

## 4. Target Architecture

### 4.1 High-Level Unified Pipeline

All read paths become:

```text
session
  ↓
plan lowering
  ↓
route planning (mode + capabilities)
  ↓
execution kernel
        ↓
   resolve ordered key stream
        ↓
   apply cursor boundary (continuation contract)
        ↓
   apply effective window contract
        ↓
   apply predicate program (index or entity)
        ↓
   apply distinct (if needed)
        ↓
   fetch rows if required by input mode
        ↓
   feed reducer (fold/group/materializer)
        ↓
   emit result
```

Window/cursor clarification:

- Cursor boundary is applied at the key-stream level.
- Offset/limit enforcement may occur at key-stream level or post-materialization depending on execution mode and terminal semantics.
- The kernel owns this decision so reducers do not implement window/cursor policy.

There is exactly one engine that owns:

- Predicate compile decision
- Access stream resolution
- Retry logic
- Budget enforcement
- `DISTINCT` wrapping
- Streaming/materialization switch

Everything else becomes a reducer plugged into the kernel.

## 5. Execution Kernel Abstraction

Introduce:

```rust
enum StreamInputMode {
    KeyOnly,
    RowOnly,
    KeyThenRow,
}

enum StreamItem<'a, E> {
    Key(&'a DataKey),
    Row(&'a E),
}

trait Reducer<E> {
    type Output;
    const INPUT_MODE: StreamInputMode;

    fn on_item(&mut self, item: StreamItem<'_, E>) -> Control;
    fn finish(self) -> Result<Self::Output>;
}
```

`Control` includes:

- `Continue`
- `StopEarly`
- `NeedsFullMaterialization`

Examples:

| Operation | Reducer |
| --- | --- |
| `load` | `RowCollector` |
| `count` | `CountFold` |
| `exists` | `ExistsFold` |
| `min` / `max` | `ExtremumFold` |
| `count_distinct_by` | `DistinctCountFold` |
| `values_by` | `ProjectionCollector` |
| `nth_by` | `RankedCollector` |
| future `group_by` (0.31) | `GroupingFold` |

This removes separate aggregate orchestration.

### 5.1 Key vs Row Phase Semantics (0.30 Lock)

0.30 explicitly preserves current eager row materialization semantics.

Execution phases:

1. kernel resolves the ordered key stream from `ExecutionPlan.access`
2. kernel applies cursor boundary and the effective window contract at the key-stream phase when required
3. kernel applies key-phase decorators (including `DISTINCT`)
4. kernel emits reducer items according to `Reducer::INPUT_MODE`
5. if item mode includes rows (`RowOnly` / `KeyThenRow`), kernel eagerly fetches row bytes for each surviving key before delivering row items
6. kernel applies remaining mode-specific budget/window contracts and finalizes reducer output

Contract rules:

- `KeyOnly`: reducer receives key items only
- `RowOnly`: reducer receives row items only
- `KeyThenRow`: reducer receives key then row for each surviving key
- reducers do not demand new item kinds dynamically at runtime; input mode is declared by `INPUT_MODE`
- kernel does not expose lazy row fetch callbacks to reducers in 0.30
- pull-based row streaming/prefetch tuning is deferred to post-0.30 work
- `StreamItem` references are borrowed from kernel-owned staging buffers and are valid only for the active `on_item` call
- reducers must not retain `StreamItem` references across calls; copy owned data when persistence is required
- if reducer returns `NeedsFullMaterialization`, kernel decides whether to replay with materialized data; reducers never execute retry logic
- kernel may restart reducer execution from scratch with a different mode after `NeedsFullMaterialization`; reducers must be restart-safe and deterministic

### 5.2 Reducer Categories

Execution uses one reducer interface but two conceptual categories:

1. `StreamingFold` (no unbounded buffering required)
   - `count`
   - `exists`
   - `min` / `max`
2. `MaterializingReducer` (buffering/collection required)
   - `load`
   - `values_by`
   - `nth_by` / ranked collectors

`count_distinct_by` may run in either category depending on access shape and fallback path, but retry/materialization policy remains kernel-owned.

## 6. Unifying Load and Aggregate

Current state:

- Load and aggregate dispatch differently after route planning.

0.30 target:

- Route produces `ExecutionPlan`.
- `ExecutionKernel` consumes `ExecutionPlan + Reducer`.
- No separate aggregate pipeline.

### 6.1 Route -> Kernel Contract (Required Artifact)

`ExecutionPlan` is the only semantic handoff artifact between route and kernel:

```rust
pub(crate) struct ExecutionPlan {
    pub access: AccessShape,
    pub direction: Direction,
    pub window: WindowSpec,
    pub distinct: DistinctSpec,
    pub capability: CapabilityFlags,
    pub hint: ScanHintPlan,
}
```

Field ownership:

- `access`: selected physical access shape (full scan, index range, composite, etc.)
- `direction`: canonical traversal direction for the access shape
- `window`: effective window contract (offset/limit/cursor boundary)
- `distinct`: distinct intent contract for this execution
- `capability`: route-computed capability envelope used by kernel decisions
- `hint`: scan-budget and total-hint plan from routing

### 6.2 Boundary Rules (Anti-Drift)

Route owns:

- plan interpretation
- access selection
- direction/window/distinct semantics
- capability derivation

Kernel owns:

- stream resolution from `ExecutionPlan.access`
- predicate compile mode choice within `ExecutionPlan.capability`
- retry execution
- budget accounting and reducer orchestration

Forbidden behavior:

- kernel must not re-derive route semantics from logical plan inputs
- kernel must not overwrite `direction`, `window`, or `distinct` semantics
- route must not perform predicate program execution, distinct wrapping, or retry orchestration

Enforcement target:

- kernel entrypoints accept `ExecutionPlan` only (not logical plan + route fragments)
- any route/kernel semantic split change must be represented by a new `ExecutionPlan` field, not hidden recomputation

Example:

```rust
kernel.execute(plan, CountFold::new())
kernel.execute(plan, RowCollector::new())
kernel.execute(plan, DistinctCountFold::new(field))
```

## 7. Predicate Compile Ownership

Move strict/subset compile decisions entirely into the kernel.

Route planner responsibility:

- Determine access shape + capability flags only, and materialize them in `ExecutionPlan`

Execution kernel responsibility:

- Decide compile mode
- Apply index program when available
- Own fallback retry
- Emit trace information

This eliminates duplicated compile logic.

## 8. DISTINCT Unification

`DISTINCT` is a key-stream decorator owned by the kernel.

Execution position:

- after access-stream resolution
- before reducer delivery (`on_item`)

Invariants:

- reducers are unaware of `DISTINCT` and never implement dedupe policy
- no aggregate-specific or load-specific DISTINCT wrapping paths
- ordering/comparator contracts for DISTINCT remain a key-stream concern

## 9. Residual Retry Centralization

Retry logic currently appears in multiple modules.

In 0.30:

- Retry lives in the execution kernel
- Reducers never implement retry
- Reducers may signal `NeedsFullMaterialization`, but they never choose replay policy
- Kernel replays access resolution when needed
- Single retry authority

## 9a. Kernel Contract Invariants

Reducers must satisfy:

- deterministic behavior for identical item sequence input
- no mutation of `ExecutionPlan`
- no IO or storage access side effects
- no routing/access-path mutation
- no predicate compilation, DISTINCT policy, or budget policy ownership

Kernel exclusively owns:

- retry policy and replay execution
- predicate compile mode selection and execution
- DISTINCT decoration
- budget enforcement
- cursor/window slicing and continuation emission

## 9b. Behavioral Parity Requirements

0.30 unification must preserve:

- identical cursor continuation token behavior for unchanged query/window shapes
- identical row ordering semantics for equivalent plans
- identical strict-vs-subset compile-mode routing outcomes
- identical DISTINCT behavior and comparator semantics
- identical budget exhaustion behavior and accounting

## 10. 0.31 GROUP BY Enablement Boundary

Once the kernel is unified, `GROUP BY` can be implemented in 0.31 as:

- `GroupingFold<K, Agg>`
- `K` = group key extractor
- `Agg` = inner aggregate fold

No new execution path should be required in 0.31 if 0.30 unification is completed. Paging grouped results should remain a kernel-level concern.

Without kernel unification, `GROUP BY` would multiply execution flows.

0.31 prerequisite carried from 0.30 hardening:

- canonical group-key encoding and ordering rules
- stable group-key hashing/fingerprinting aligned with existing coercion + canonical comparison semantics

## 11. Structural Refactors in 0.30

### 11.1 Split Complexity Hotspots

`route/planner/`:

- Split into `capability.rs`
- Split into `mode.rs`
- Split into `fast_path.rs`
- Split into `hints.rs`

### 11.2 Retire Legacy Aggregate Facades

`load/aggregate/mod.rs`:

- Keep as a thin module root only while reducer migration is in progress
- Delete remaining orchestration-wrapper facades after reducers are the sole aggregate execution entry

### 11.3 Split Ordered Key Stream Concerns

`ordered_key_stream.rs`:

- Separate stream normalization
- Separate comparator logic
- Separate distinct logic
- Separate monotonicity guards

As of `0.30` in-tree progress, DISTINCT stream logic has been moved under `executor/kernel/distinct.rs`.

## 12. Migration Strategy

### Phase 1

- Introduce `execution_plan.rs` with the canonical `ExecutionPlan` route->kernel contract
- Introduce canonical reducer item contracts (`StreamInputMode`, `StreamItem`, `Control`)
- Introduce `ExecutionKernel` behind existing APIs
- Keep old aggregate functions, but delegate internally to kernel
- Preserve eager row materialization semantics (no lazy row-fetch rewrite in this phase)

### Phase 2

- Remove duplicate aggregate orchestration
- [landed] Delete `count_distinct` hybrid path
- [landed] Converge aggregate streaming input preparation into one setup boundary
- [landed] Converge aggregate fast-path fold wiring into shared helpers
- [landed] Converge aggregate materialized terminal orchestration into one shared helper
- [landed] Converge aggregate routed-stream resolution and fold wiring into one shared helper
- [landed] Converge secondary-index aggregate probe/fallback fold wiring into one shared helper
- [landed] Move aggregate execution entrypoint orchestration to `ExecutionKernel::execute_aggregate_spec`
- [landed] Move aggregate immediate-vs-streaming reducer selection into one kernel adapter boundary
- [landed] Kernel is the sole interpreter of `AggregateSpec` dispatch (including `target_field`)
- [landed] Materialized aggregate dispatch ownership moved to kernel; load-layer `spec.target_field()` branching removed
- [landed] Remove duplicate legacy aggregate kernel orchestration function
- [landed] Extract aggregate kernel orchestration helpers into `executor/kernel/aggregate.rs`
- [landed] Split aggregate terminal wrappers into `load/aggregate/terminals.rs`
- [landed] Aggregate fast-path orchestration is kernel-owned in `executor/kernel/aggregate.rs`
- [landed] Split aggregate contracts into `load/aggregate/contracts.rs`, then deleted legacy `load/aggregate/orchestration.rs` after moving aggregate descriptor/setup + dispatch fully to kernel-owned boundaries
- [landed] Route planner decomposition into focused modules (`planner/{capability,fast_path,hints,mode}.rs`)

### Phase 3

- Collapse terminal wrappers to reducer adapters
- Cursor-module consolidation so continuation, boundary validation, and window contracts are kernel-aligned

### Phase 4

- Remove legacy execution entrypoints

Tests should continue to pass unchanged.

## 13. Risk Assessment

| Area | Risk | Mitigation |
| --- | --- | --- |
| Kernel introduction | Medium | Land behind existing APIs first and preserve behavior through parity tests |
| Removing legacy aggregate facades | Medium-high | Delete wrappers only after reducers are the sole aggregate execution entry |
| Preserving cursor + window parity | High | Lock continuation-token bytes, cursor signatures, and paging parity with golden tests |
| Eliminating remaining aggregate special dispatch branches | Medium | Keep existing semantics and scan-budget parity tests while converging branch-local orchestration |
| Planner split refactor | Low | Pure file decomposition with no semantic ownership change |

Highest-risk boundary in 0.30:

- cursor + window parity; silent regressions are most likely here if continuation and window contracts are not test-locked

## 14. Hard-Mode Pre-Merge Checklist

Before merging 0.30, all must be true:

- all aggregate tests pass unchanged
- all pagination tests pass unchanged
- cursor signature/continuation token bytes are identical before/after for unchanged query shapes
- route trace output is identical before/after for unchanged plans
- benchmark shows no regression greater than 5% on common scan workloads
- no new `Vec` allocations are introduced in documented hot paths
- golden tests exist for continuation-token equality
- golden tests exist for strict-vs-subset compile route-decision logs

## 15. Success Criteria for 0.30

- Route->kernel `ExecutionPlan` contract is explicit and canonical
- Kernel does not re-derive direction/window/distinct semantics outside `ExecutionPlan`
- 0.30 keeps eager row materialization semantics; no half-streaming row-fetch path is introduced
- Retry policy is kernel-owned; reducers never own replay decisions
- Kernel contract invariants are test-locked
- Behavioral parity requirements are test-locked
- No parallel load/aggregate execution pipelines
- `count_distinct_by` is not special-cased
- Strict/subset compile logic exists in one place
- Residual retry logic exists in one place
- `DISTINCT` wrapping exists in one place
- route planner remains split into focused modules (`planner/{capability,fast_path,hints,mode}.rs`)
- legacy `load/aggregate` orchestration wrappers are removed once reducers are the only aggregate execution entry

## 16. What 0.30 Enables

After this:

- 0.31 `GROUP BY` implementation on top of the unified kernel
- Incremental streaming window improvements
- Memory-aware grouping (0.31+)
- Smarter pushdown logic
- Simpler future aggregate additions
- Potential async/pull-based engine in 0.31+

## 17. Definition of Done (Strict)

0.30 is complete only when all are true:

- exactly one kernel-owned module is permitted to call `resolve_physical_key_stream` (enforced via visibility and/or structural guard)
- there is exactly one place in the codebase that applies `DISTINCT`
- there is exactly one place in the codebase that applies residual retry
- there is exactly one place in the codebase that applies predicate compile logic
- legacy `load/aggregate` orchestration wrappers are deleted once reducers are the only aggregate entry
- `count_distinct_by` has no unique execution path
- `ExecutionKernel` owns all read execution
- for read execution paths, no module outside route planning + kernel internals inspects `AccessPath` internals directly

## 18. Version Narrative

- 0.29: Routing consolidation + hardening
- 0.30: Execution kernel unification
- 0.31: `GROUP BY` + deeper streaming work
